ä¸‹é¢æˆ‘æ ¹æ®ä½ æœ€æ–°çš„éœ€æ±‚ **é‡æ–°æ•´ç†ã€é‡å†™å¹¶å¼ºåŒ–ä½ çš„æŒ‡ä»¤**ï¼Œä½¿å…¶å˜æˆä¸€ä¸ª **æ¸…æ™°ã€å¯æ‰§è¡Œã€æ— æ­§ä¹‰ã€å¯ç›´æ¥äº¤ç»™å·¥ç¨‹å¸ˆæˆ– LLM æ‰§è¡Œ**çš„ç‰ˆæœ¬ã€‚

æˆ‘ä¼šç»™ä½ ä¸¤ç‰ˆï¼š

1. **æ™®é€šä¸­æ–‡ç‰ˆæœ¬ï¼ˆæœ€æ¸…æ™°ï¼‰**
2. **é€‚åˆè®© AI ç›´æ¥æ‰§è¡Œçš„â€œLLM æŒ‡ä»¤ç‰ˆæœ¬â€ï¼ˆæ›´ä¸¥æ ¼æ ¼å¼åŒ–ï¼‰**

---

# âœ… **ï¼ˆAï¼‰é‡æ–°æ•´ç†åçš„æ›´æ¸…æ™°ã€ä¸“ä¸šçš„æŒ‡ä»¤ï¼ˆæ¨èç»™ä½ è‡ªå·±ä½¿ç”¨ï¼‰**

ä¸‹é¢æ˜¯æ”¹è¿›åçš„æ•´ä½“ä»»åŠ¡æè¿°ï¼š

---

## **ğŸ¯ ä»»åŠ¡ç›®æ ‡**

éœ€è¦ç¼–å†™ä¸€ä¸ªè„šæœ¬ï¼Œå¯¹ç°æœ‰çš„ `chunks.parquet` ä¸­çš„çˆ¶ chunkï¼ˆparent chunksï¼‰è¿›è¡Œé‡æ–°åˆ’åˆ†ï¼Œä½¿æ¯ä¸ªçˆ¶ chunk çš„é•¿åº¦ä¸è¶…è¿‡ **256 token**ã€‚

åœ¨é‡æ–°ç”Ÿæˆçˆ¶ chunk æ—¶ï¼š

* çˆ¶ chunk çš„å­—ç¬¦ç´¢å¼•ï¼ˆ`start_char` / `end_char`ï¼‰å¿…é¡»ä¿æŒä¸ `documents_cleaned.parquet` ä¸­çš„åŸå§‹ `text` å®Œå…¨ä¸€è‡´ã€‚
* **ä¸èƒ½å¯¹ text åšä»»ä½•ä¿®æ”¹**ï¼ˆä¾‹å¦‚å»é™¤ç©ºæ ¼ã€æ›¿æ¢å­—ç¬¦ã€æ­£åˆ™æ¸…æ´—ç­‰ï¼‰ï¼Œå¦åˆ™çˆ¶å­ chunk çš„å­—ç¬¦å®šä½ä¼šé”™ä¹±ã€‚
* åœ¨é‡æ–°åˆ‡åˆ†çˆ¶ chunk æ—¶ï¼Œè¦ä¼˜å…ˆä¿è¯ **è¯­ä¹‰å•å…ƒå®Œæ•´æ€§**ï¼Œåˆ†å‰²ç‚¹å°½é‡é è¿‘ï¼š

  * å¥å·ï¼ˆã€‚ï¼.ï¼‰
  * æ¢è¡Œç¬¦
  * ä¸­æ–‡å¥æœ«æ ‡ç‚¹ï¼ˆï¼ï¼Ÿï¼Œï¼›ï¼‰
  * è‹±æ–‡å¥æœ«æ ‡ç‚¹ (.!?)
  * å…¶ä»–è‡ªç„¶å¥è¾¹ç•Œ

---

## **ğŸ“¦ è¾“å…¥æ–‡ä»¶**

1. `data/processed/documents_cleaned.parquet`

   * åŒ…å«å­—æ®µï¼š`doc_id`, `text`
2. `data/processed/chunks.parquet`

   * åŒ…å«å­—æ®µï¼š`doc_id`, `chunk_id`, `is_parent`, `start_char`, `end_char`, `token_count` ç­‰
   * å…¶ä¸­çš„ **parent chunk çš„å®šä½éœ€è¦è¢«é‡æ–°è°ƒæ•´**


## **ğŸ”— çˆ¶å­ chunk çš„æ˜ å°„ï¼ˆä½ ç»™çš„ç®—æ³•ï¼‰**

ä½ ä¸éœ€è¦ç®€å•çš„ä¸­å¿ƒç‚¹ï¼ˆchild_centerï¼‰ï¼Œè€Œæ˜¯è¦ï¼š

### **1) ä¼˜å…ˆé€‰æ‹©â€œå®Œå…¨åŒ…å«â€çˆ¶ chunk**

```python
if p.start_char <= c.start_char and c.end_char <= p.end_char
```

### **2) è‹¥æ— å®Œå…¨åŒ…å«ï¼Œåˆ™é€‰æ‹©â€œæœ€å¤§å­—ç¬¦ overlapâ€çš„çˆ¶ chunk**

ä½ æä¾›çš„ç®—æ³•å·²ç»å¾ˆå¥½ï¼Œæˆ‘æ ¼å¼åŒ–æˆæ›´æ¸…æ™°ç‰ˆæœ¬ï¼š

```python
def map_child_to_parent(parent_chunks, child_positions):
    mapping = []
    for cstart, cend in child_positions:
        # 1. å®Œå…¨åŒ…å«ä¼˜å…ˆ
        found = False
        for pidx, p in enumerate(parent_chunks):
            if p['start_char'] <= cstart and cend <= p['end_char']:
                mapping.append(pidx)
                found = True
                break
        if found:
            continue

        # 2. æœ€å¤§ overlap æ¬¡ä¹‹
        best, best_ov = None, 0
        for pidx, p in enumerate(parent_chunks):
            overlap = max(0, min(cend, p['end_char']) - max(cstart, p['start_char']))
            if overlap > best_ov:
                best_ov = overlap
                best = pidx

        mapping.append(best if best is not None else -1)

    return mapping
