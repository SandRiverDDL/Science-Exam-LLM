"""æµ‹è¯•embeddingæ„å»ºæµç¨‹"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root / "src"))


def test_parquet_loading():
    """æµ‹è¯•Parquetæ–‡ä»¶åŠ è½½"""
    import pyarrow.parquet as pq
    
    parquet_dir = "data/processed/parquet/chunks"
    
    if not os.path.exists(parquet_dir):
        print(f"âŒ Parquetç›®å½•ä¸å­˜åœ¨: {parquet_dir}")
        return
    
    parquet_files = sorted(Path(parquet_dir).glob("chunks_*.parquet"))
    
    if not parquet_files:
        print(f"âŒ æœªæ‰¾åˆ°chunks Parquetæ–‡ä»¶")
        return
    
    print("=" * 80)
    print("æµ‹è¯•Parquetæ–‡ä»¶åŠ è½½")
    print("=" * 80)
    
    # è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶
    first_file = parquet_files[0]
    print(f"\nè¯»å–æ–‡ä»¶: {first_file}")
    
    table = pq.read_table(str(first_file))
    df = table.to_pandas()
    
    print(f"\nğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
    print(f"  æ€»è¡Œæ•°: {len(df):,}")
    print(f"  åˆ—å: {df.columns.tolist()}")
    
    print(f"\nğŸ“‹ Schema:")
    print(table.schema)
    
    print(f"\nğŸ“ å‰3è¡Œç¤ºä¾‹:")
    for idx, row in df.head(3).iterrows():
        print(f"\n  [{idx}] chunk_id: {row['chunk_id']}")
        print(f"      doc_id: {row['doc_id']}")
        print(f"      chunk_len: {row['chunk_len']}")
        print(f"      child_ids: {row['child_ids'][:10]}... (å…±{len(row['child_ids'])}ä¸ª)")
        print(f"      rerank_text: {row['rerank_text'][:80]}...")
    
    print("\n" + "=" * 80)
    print("âœ… Parquetæ–‡ä»¶åŠ è½½æµ‹è¯•é€šè¿‡")


def test_embedding_model():
    """æµ‹è¯•embeddingæ¨¡å‹åŠ è½½å’Œæ¨ç†"""
    import torch
    from retrieval.embedding_hf import HFTextEmbedding
    
    print("=" * 80)
    print("æµ‹è¯•BGE-smallæ¨¡å‹")
    print("=" * 80)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"\nè®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    print("\nåŠ è½½æ¨¡å‹...")
    model = HFTextEmbedding(
        model_id="BAAI/bge-small-en-v1.5",
        device=device,
        max_length=256,
        dtype="float16",
    )
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # æµ‹è¯•æ–‡æœ¬åµŒå…¥
    print("\næµ‹è¯•æ–‡æœ¬åµŒå…¥...")
    test_texts = [
        "What is machine learning?",
        "How does deep learning work?",
    ]
    
    embeddings = model._embed_batch(test_texts)
    print(f"  è¾“å‡ºå½¢çŠ¶: {embeddings.shape}")
    print(f"  æ•°æ®ç±»å‹: {embeddings.dtype}")
    print(f"  å‘é‡ç»´åº¦: {embeddings.shape[1]}")
    
    # æµ‹è¯•token IDsåµŒå…¥
    print("\næµ‹è¯•token IDsåµŒå…¥...")
    test_ids = [
        [101, 2054, 2003, 3698, 4083, 1029, 102],  # æ¨¡æ‹Ÿtoken ids
        [101, 2129, 2515, 2784, 4083, 2147, 1029, 102],
    ]
    
    embeddings_ids = model._embed_batch_ids(test_ids)
    print(f"  è¾“å‡ºå½¢çŠ¶: {embeddings_ids.shape}")
    print(f"  æ•°æ®ç±»å‹: {embeddings_ids.dtype}")
    print(f"  å‘é‡ç»´åº¦: {embeddings_ids.shape[1]}")
    
    print("\n" + "=" * 80)
    print("âœ… Embeddingæ¨¡å‹æµ‹è¯•é€šè¿‡")


def test_faiss_index():
    """æµ‹è¯•FAISSç´¢å¼•åˆ›å»º"""
    import numpy as np
    import faiss
    
    print("=" * 80)
    print("æµ‹è¯•FAISSç´¢å¼•")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•å‘é‡
    dim = 384  # BGE-smallç»´åº¦
    n_vectors = 100
    
    print(f"\nåˆ›å»ºæµ‹è¯•å‘é‡: {n_vectors}ä¸ª, ç»´åº¦={dim}")
    vectors = np.random.randn(n_vectors, dim).astype(np.float32)
    
    # å½’ä¸€åŒ–
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    vectors = vectors / np.clip(norms, 1e-9, None)
    
    # åˆ›å»ºIndexFlatIP
    print("\nåˆ›å»ºIndexFlatIP...")
    index = faiss.IndexFlatIP(dim)
    
    # æ·»åŠ å‘é‡
    index.add(vectors)
    print(f"  ç´¢å¼•å‘é‡æ•°: {index.ntotal}")
    
    # æµ‹è¯•æ£€ç´¢
    print("\næµ‹è¯•æ£€ç´¢...")
    query = vectors[:1]  # ç¬¬ä¸€ä¸ªå‘é‡ä½œä¸ºquery
    k = 5
    
    distances, indices = index.search(query, k)
    print(f"  Top-{k} ç›¸ä¼¼åº¦: {distances[0]}")
    print(f"  Top-{k} ç´¢å¼•: {indices[0]}")
    
    print("\n" + "=" * 80)
    print("âœ… FAISSç´¢å¼•æµ‹è¯•é€šè¿‡")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" * 2)
    print("ğŸš€ å¼€å§‹æµ‹è¯•Embeddingæ„å»ºæµç¨‹")
    print("\n")
    
    try:
        # æµ‹è¯•1: ParquetåŠ è½½
        test_parquet_loading()
        print("\n" * 2)
        
        # æµ‹è¯•2: Embeddingæ¨¡å‹
        test_embedding_model()
        print("\n" * 2)
        
        # æµ‹è¯•3: FAISSç´¢å¼•
        test_faiss_index()
        print("\n" * 2)
        
        print("=" * 80)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥è¿è¡Œ build_embeddings.py æ„å»ºç´¢å¼•")
        print("=" * 80)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
