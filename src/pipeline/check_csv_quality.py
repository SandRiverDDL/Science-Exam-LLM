"""
æ£€æŸ¥CSV/Parquetæ–‡ä»¶ä¸­çš„wikiæ•°æ®è´¨é‡

åŠŸèƒ½ï¼š
1. è¯»å–CSVæˆ–Parquetæ–‡ä»¶
2. åº”ç”¨æ–‡æœ¬æ¸…æ´—è§„åˆ™
3. ç­›é€‰å‡ºé•¿åº¦å¤§äº32å­—ç¬¦çš„æ–‡æœ¬
4. æ‰“å°å‰20è¡Œä¾›äººå·¥æ£€æŸ¥
"""

import os
import sys
import csv
import pyarrow.parquet as pq
from pathlib import Path
from typing import List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root / "src"))

from processing.text_cleaner import full_text_cleaning, filter_short_text
from processing.title_cleaner import process_title, is_good_title, clean_title_conservative
from transformers import AutoTokenizer


def read_csv_with_cleaning(
    csv_path: str,
    min_length: int = 32,
    max_rows: int = 20,
    text_columns: List[str] = None
) -> List[Tuple[str, str, str]]:
    """
    è¯»å–CSVæ–‡ä»¶å¹¶åº”ç”¨æ¸…æ´—è§„åˆ™
    
    Args:
        csv_path: CSVæ–‡ä»¶è·¯å¾„
        min_length: æœ€å°å­—ç¬¦é•¿åº¦
        max_rows: æœ€å¤šæ˜¾ç¤ºè¡Œæ•°
        text_columns: æ–‡æœ¬åˆ—åï¼ˆNoneåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
    
    Returns:
        [(row_id, title, cleaned_text), ...]
    """
    # åˆå§‹åŒ–tokenizerï¼ˆç”¨äºtokenè®¡æ•°ï¼‰
    tokenizer = AutoTokenizer.from_pretrained(
        "BAAI/bge-small-en-v1.5",
        trust_remote_code=True
    )
    
    results = []
    
    # æå‡CSVå­—æ®µå¤§å°é™åˆ¶
    try:
        csv.field_size_limit(min(sys.maxsize, 1_000_000_000))
    except Exception:
        pass
    
    # è¯»å–CSV
    with open(csv_path, 'r', encoding='utf-8', errors='ignore', newline='') as f:
        reader = csv.DictReader(f)
        header = reader.fieldnames or []
        
        # è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬åˆ—
        if text_columns is None:
            candidates = {"text", "content", "article", "body", "paragraph", "desc", "description", "wiki_text"}
            text_columns = [h for h in header if h and h.lower() in candidates]
            if not text_columns:
                text_columns = [h for h in header if "text" in h.lower()]
            if not text_columns:
                text_columns = header[:3]  # é»˜è®¤å‰3åˆ—
        
        # æ£€æµ‹æ ‡é¢˜åˆ—
        title_columns = [h for h in header if h and h.lower() in {"title", "name", "heading", "subject"}]
        
        print(f"æ£€æµ‹åˆ°çš„æ–‡æœ¬åˆ—: {text_columns}")
        print(f"æ£€æµ‹åˆ°çš„æ ‡é¢˜åˆ—: {title_columns}")
        print("=" * 80)
        
        for i, row in enumerate(reader):
            if len(results) >= max_rows:
                break
            
            # æå–æ ‡é¢˜
            title = ""
            for col in title_columns:
                val = row.get(col, "")
                if isinstance(val, str) and val.strip():
                    title = val.strip()
                    break
            
            # æå–æ–‡æœ¬
            parts = []
            for col in text_columns:
                val = row.get(col, "")
                if isinstance(val, str) and val.strip():
                    parts.append(val.strip())
            
            text = "\n\n".join(parts).strip()
            
            if not text:
                continue
            
            # åº”ç”¨æ–‡æœ¬æ¸…æ´—
            cleaned_text = full_text_cleaning(text, target_lang="en")
            
            # å¦‚æœæ¸…æ´—åä¸ºNoneï¼Œè¯´æ˜æ˜¯åƒåœ¾æ–‡æœ¬
            if cleaned_text is None:
                continue
            
            # è¿‡æ»¤é•¿åº¦
            if len(cleaned_text) < min_length:
                continue
            
            # æ¸…æ´—æ ‡é¢˜
            cleaned_title = ""
            if title and is_good_title(title):
                cleaned_title = clean_title_conservative(title)
            
            row_id = f"Row {i + 1}"
            results.append((row_id, cleaned_title, cleaned_text))
    
    return results


def read_parquet_with_cleaning(
    parquet_path: str,
    min_length: int = 32,
    max_rows: int = 20,
    text_columns: List[str] = None
) -> List[Tuple[str, str, str]]:
    """
    è¯»å–Parquetæ–‡ä»¶å¹¶åº”ç”¨æ¸…æ´—è§„åˆ™
    
    Args:
        parquet_path: Parquetæ–‡ä»¶è·¯å¾„
        min_length: æœ€å°å­—ç¬¦é•¿åº¦
        max_rows: æœ€å¤šæ˜¾ç¤ºè¡Œæ•°
        text_columns: æ–‡æœ¬åˆ—åï¼ˆNoneåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
    
    Returns:
        [(row_id, title, cleaned_text), ...]
    """
    # åˆå§‹åŒ–tokenizerï¼ˆç”¨äºtokenè®¡æ•°ï¼‰
    tokenizer = AutoTokenizer.from_pretrained(
        "BAAI/bge-small-en-v1.5",
        trust_remote_code=True
    )
    
    results = []
    
    # è¯»å–Parquetæ–‡ä»¶
    table = pq.read_table(parquet_path)
    df = table.to_pandas()
    
    # è·å–æ‰€æœ‰åˆ—å
    header = df.columns.tolist()
    
    print(f"\næ–‡ä»¶åŒ…å«çš„æ‰€æœ‰åˆ—: {header}")
    print(f"æ€»è¡Œæ•°: {len(df):,}")
    print("=" * 80)
    
    # è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬åˆ—
    if text_columns is None:
        candidates = {"text", "content", "article", "body", "paragraph", "desc", "description", "wiki_text", "page_content"}
        text_columns = [h for h in header if h and h.lower() in candidates]
        if not text_columns:
            # æŸ¥æ‰¾åŒ…å«"text"å…³é”®å­—çš„åˆ—
            text_columns = [h for h in header if "text" in h.lower()]
        if not text_columns:
            # æŸ¥æ‰¾åŒ…å«"content"å…³é”®å­—çš„åˆ—
            text_columns = [h for h in header if "content" in h.lower()]
        if not text_columns:
            # é»˜è®¤ä½¿ç”¨å‰3åˆ—ï¼ˆæ’é™¤æ˜æ˜¾çš„IDåˆ—ï¼‰
            non_id_cols = [h for h in header if not any(x in h.lower() for x in ["id", "index", "_id"])]
            text_columns = non_id_cols[:3] if non_id_cols else header[:3]
    
    # æ£€æµ‹æ ‡é¢˜åˆ—
    title_columns = [h for h in header if h and h.lower() in {"title", "name", "heading", "subject", "page_title"}]
    
    print(f"æ£€æµ‹åˆ°çš„æ–‡æœ¬åˆ—: {text_columns}")
    print(f"æ£€æµ‹åˆ°çš„æ ‡é¢˜åˆ—: {title_columns}")
    print("=" * 80)
    
    # éå†è¡Œ
    for i, row in df.iterrows():
        if len(results) >= max_rows:
            break
        
        # æå–æ ‡é¢˜
        title = ""
        for col in title_columns:
            if col in df.columns:
                val = row[col]
                if isinstance(val, str) and val.strip():
                    title = val.strip()
                    break
                elif val is not None:
                    title = str(val).strip()
                    if title:
                        break
        
        # æå–æ–‡æœ¬
        parts = []
        for col in text_columns:
            if col in df.columns:
                val = row[col]
                if isinstance(val, str) and val.strip():
                    parts.append(val.strip())
                elif val is not None:
                    val_str = str(val).strip()
                    if val_str and val_str != "nan":
                        parts.append(val_str)
        
        text = "\n\n".join(parts).strip()
        
        if not text:
            continue
        
        # åº”ç”¨æ–‡æœ¬æ¸…æ´—
        cleaned_text = full_text_cleaning(text, target_lang="en")
        
        # å¦‚æœæ¸…æ´—åä¸ºNoneï¼Œè¯´æ˜æ˜¯åƒåœ¾æ–‡æœ¬
        if cleaned_text is None:
            continue
        
        # è¿‡æ»¤é•¿åº¦
        if len(cleaned_text) < min_length:
            continue
        
        # æ¸…æ´—æ ‡é¢˜
        cleaned_title = ""
        if title and is_good_title(title):
            cleaned_title = clean_title_conservative(title)
        
        row_id = f"Row {i}"
        results.append((row_id, cleaned_title, cleaned_text))
    
    return results


def print_results(results: List[Tuple[str, str, str]]):
    """æ‰“å°æ£€æŸ¥ç»“æœ"""
    print(f"\næ‰¾åˆ° {len(results)} æ¡ç¬¦åˆæ¡ä»¶çš„è®°å½•ï¼ˆé•¿åº¦ >= 32å­—ç¬¦ï¼‰\n")
    print("=" * 80)
    
    for i, (row_id, title, text) in enumerate(results, 1):
        print(f"\nã€{i}ã€‘{row_id}")
        
        if title:
            print(f"æ ‡é¢˜: {title}")
        
        # æ˜¾ç¤ºæ–‡æœ¬ï¼ˆæœ€å¤šæ˜¾ç¤º500å­—ç¬¦ï¼‰
        text_preview = text[:500] if len(text) > 500 else text
        if len(text) > 500:
            text_preview += "..."
        
        print(f"é•¿åº¦: {len(text)} å­—ç¬¦")
        print(f"æ–‡æœ¬é¢„è§ˆ:\n{text_preview}")
        print("-" * 80)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ£€æŸ¥CSV/Parquetæ–‡ä»¶ä¸­çš„wikiæ•°æ®è´¨é‡')
    parser.add_argument('file', help='CSVæˆ–Parquetæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ 1.csv æˆ– 0_to_25000.parquetï¼‰')
    parser.add_argument('--min-length', type=int, default=32, help='æœ€å°å­—ç¬¦é•¿åº¦ï¼ˆé»˜è®¤32ï¼‰')
    parser.add_argument('--max-rows', type=int, default=20, help='æœ€å¤šæ˜¾ç¤ºè¡Œæ•°ï¼ˆé»˜è®¤20ï¼‰')
    parser.add_argument('--columns', nargs='+', help='æŒ‡å®šæ–‡æœ¬åˆ—åï¼ˆå¯é€‰ï¼Œå¤šåˆ—ç”¨ç©ºæ ¼åˆ†éš”ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.file):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {args.file}")
        return
    
    # åˆ¤æ–­æ–‡ä»¶ç±»å‹
    file_ext = os.path.splitext(args.file)[1].lower()
    is_parquet = file_ext == '.parquet'
    
    print(f"æ­£åœ¨æ£€æŸ¥æ–‡ä»¶: {args.file}")
    print(f"æ–‡ä»¶ç±»å‹: {'Parquet' if is_parquet else 'CSV'}")
    print(f"ç­›é€‰æ¡ä»¶: é•¿åº¦ >= {args.min_length} å­—ç¬¦")
    print(f"æ˜¾ç¤ºæ•°é‡: å‰ {args.max_rows} è¡Œ")
    print("=" * 80)
    
    # è¯»å–å¹¶æ¸…æ´—
    if is_parquet:
        results = read_parquet_with_cleaning(
            args.file,
            min_length=args.min_length,
            max_rows=args.max_rows,
            text_columns=args.columns
        )
    else:
        results = read_csv_with_cleaning(
            args.file,
            min_length=args.min_length,
            max_rows=args.max_rows,
            text_columns=args.columns
        )
    
    # æ‰“å°ç»“æœ
    print_results(results)
    
    # æ•°æ®ä¸»é¢˜åˆ†ææç¤º
    print("\n" + "=" * 80)
    print("ğŸ’¡ æ•°æ®ä¸»é¢˜æ£€æŸ¥å»ºè®®ï¼š")
    print("1. æŸ¥çœ‹ä¸Šè¿°æ–‡æœ¬æ˜¯å¦ä¸ç§‘å­¦ä¸»é¢˜ç›¸å…³ï¼ˆç‰©ç†ã€åŒ–å­¦ã€ç”Ÿç‰©ã€æ•°å­¦ç­‰ï¼‰")
    print("2. å¦‚æœå¤§éƒ¨åˆ†æ–‡æœ¬ä¸ç›¸å…³ï¼Œå»ºè®®ï¼š")
    print("   - æ£€æŸ¥æ•°æ®æ¥æºæ˜¯å¦æ­£ç¡®")
    print("   - è€ƒè™‘æ·»åŠ ä¸»é¢˜è¿‡æ»¤é€»è¾‘")
    print("   - ä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼ˆscience, physics, chemistry, biologyç­‰ï¼‰")
    print("=" * 80)


if __name__ == "__main__":
    main()
